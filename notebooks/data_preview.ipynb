{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b2caee4",
   "metadata": {},
   "source": [
    "# FinGuard IntelliAgent - Synthetic Data Preview\n",
    "\n",
    "**Milestone 2: Data Generation and Validation**\n",
    "\n",
    "This notebook loads and validates the synthetic datasets generated for the FinGuard IntelliAgent project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4a7e6f",
   "metadata": {},
   "source": [
    "## Why Synthetic Data?\n",
    "\n",
    "### Purpose of Synthetic Data Generation\n",
    "\n",
    "For this ADK capstone project, we use synthetic data for several critical reasons:\n",
    "\n",
    "1. **Privacy & Compliance**\n",
    "   - Real financial SMS messages contain sensitive personal information\n",
    "   - Using synthetic data ensures GDPR and data protection compliance\n",
    "   - No risk of exposing actual customer financial data\n",
    "\n",
    "2. **Controlled Testing Environment**\n",
    "   - We can create specific edge cases and scenarios\n",
    "   - Predictable data for testing SMS parser accuracy\n",
    "   - Ability to validate agent tool behavior systematically\n",
    "\n",
    "3. **Realistic Kenyan SME Patterns**\n",
    "   - Data reflects actual M-Pesa, Paybill, and Till transaction formats\n",
    "   - Invoice patterns match typical Kenyan business cycles\n",
    "   - Receipt categories align with real SME expense structures\n",
    "\n",
    "4. **Development Efficiency**\n",
    "   - Immediate availability of diverse test data\n",
    "   - No dependencies on live transaction feeds\n",
    "   - Reproducible results for debugging and optimization\n",
    "\n",
    "5. **Demonstration & Education**\n",
    "   - Can safely demo the system without privacy concerns\n",
    "   - Helps stakeholders understand agent capabilities\n",
    "   - Provides training data for future ML enhancements\n",
    "\n",
    "### Datasets Generated\n",
    "\n",
    "- **sms.csv**: 50 synthetic M-Pesa, Bank, and mobile money transactions\n",
    "- **invoices.json**: 20 synthetic invoices with varying payment statuses\n",
    "- **receipts.json**: 15 synthetic business expense receipts\n",
    "\n",
    "These datasets will be used by:\n",
    "- **SMSParserTool** (Milestone 3): Parse and extract transaction data\n",
    "- **InsightsTool** (Milestone 4): Generate financial insights and trends\n",
    "- **InvoiceCollectionTool** (Milestone 5): Track and automate collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec779a9f",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edceb657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fcf8f9",
   "metadata": {},
   "source": [
    "## 1. SMS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33261c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SMS data\n",
    "sms_path = Path('../data/synthetic/sms.csv')\n",
    "sms_df = pd.read_csv(sms_path)\n",
    "\n",
    "print(f\"üì± SMS Dataset loaded: {len(sms_df)} records\")\n",
    "print(f\"\\nDataset shape: {sms_df.shape}\")\n",
    "print(f\"\\nColumns: {list(sms_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae37098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 5 SMS messages\n",
    "print(\"\\nüìã First 5 SMS Messages:\\n\")\n",
    "sms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64254f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMS Data Validation\n",
    "print(\"\\nüîç SMS Data Validation:\\n\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"1. Missing Values:\")\n",
    "missing = sms_df.isnull().sum()\n",
    "print(missing[missing > 0] if missing.sum() > 0 else \"   ‚úÖ No missing values\")\n",
    "\n",
    "# Check amounts are valid\n",
    "print(\"\\n2. Amount Validation:\")\n",
    "print(f\"   Min amount: KES {sms_df['amount'].min():,.2f}\")\n",
    "print(f\"   Max amount: KES {sms_df['amount'].max():,.2f}\")\n",
    "print(f\"   Mean amount: KES {sms_df['amount'].mean():,.2f}\")\n",
    "invalid_amounts = sms_df[sms_df['amount'] <= 0]\n",
    "print(f\"   Invalid amounts (‚â§0): {len(invalid_amounts)}\")\n",
    "\n",
    "# Check date validity\n",
    "print(\"\\n3. Date Validation:\")\n",
    "sms_df['date_parsed'] = pd.to_datetime(sms_df['date'], errors='coerce')\n",
    "invalid_dates = sms_df['date_parsed'].isnull().sum()\n",
    "print(f\"   Invalid dates: {invalid_dates}\")\n",
    "if invalid_dates == 0:\n",
    "    print(f\"   ‚úÖ All dates valid\")\n",
    "    print(f\"   Date range: {sms_df['date_parsed'].min().date()} to {sms_df['date_parsed'].max().date()}\")\n",
    "\n",
    "# Transaction type distribution\n",
    "print(\"\\n4. Transaction Type Distribution:\")\n",
    "trans_dist = sms_df['transaction_type'].value_counts()\n",
    "for trans_type, count in trans_dist.items():\n",
    "    percentage = (count / len(sms_df)) * 100\n",
    "    print(f\"   - {trans_type}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ed2b0",
   "metadata": {},
   "source": [
    "## 2. Invoices Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load invoices data\n",
    "invoices_path = Path('../data/synthetic/invoices.json')\n",
    "with open(invoices_path, 'r') as f:\n",
    "    invoices_data = json.load(f)\n",
    "\n",
    "invoices_df = pd.DataFrame(invoices_data)\n",
    "\n",
    "print(f\"üìÑ Invoices Dataset loaded: {len(invoices_df)} records\")\n",
    "print(f\"\\nDataset shape: {invoices_df.shape}\")\n",
    "print(f\"\\nColumns: {list(invoices_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b03cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 5 invoices\n",
    "print(\"\\nüìã First 5 Invoices:\\n\")\n",
    "invoices_df[['invoice_id', 'customer_name', 'amount', 'status', 'due_date']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07fc5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoices Data Validation\n",
    "print(\"\\nüîç Invoices Data Validation:\\n\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"1. Missing Values:\")\n",
    "missing = invoices_df.isnull().sum()\n",
    "print(missing[missing > 0] if missing.sum() > 0 else \"   ‚úÖ No missing values in critical fields\")\n",
    "\n",
    "# Check amounts are valid\n",
    "print(\"\\n2. Amount Validation:\")\n",
    "print(f\"   Min invoice: KES {invoices_df['amount'].min():,.2f}\")\n",
    "print(f\"   Max invoice: KES {invoices_df['amount'].max():,.2f}\")\n",
    "print(f\"   Total value: KES {invoices_df['amount'].sum():,.2f}\")\n",
    "print(f\"   Total paid: KES {invoices_df['amount_paid'].sum():,.2f}\")\n",
    "print(f\"   Total outstanding: KES {invoices_df['amount_outstanding'].sum():,.2f}\")\n",
    "\n",
    "# Verify amount calculations\n",
    "amount_check = invoices_df['amount'] == (invoices_df['amount_paid'] + invoices_df['amount_outstanding'])\n",
    "print(f\"   ‚úÖ Amount calculations correct: {amount_check.all()}\")\n",
    "\n",
    "# Check date validity\n",
    "print(\"\\n3. Date Validation:\")\n",
    "invoices_df['issue_date_parsed'] = pd.to_datetime(invoices_df['issue_date'], errors='coerce')\n",
    "invoices_df['due_date_parsed'] = pd.to_datetime(invoices_df['due_date'], errors='coerce')\n",
    "invalid_dates = invoices_df['issue_date_parsed'].isnull().sum() + invoices_df['due_date_parsed'].isnull().sum()\n",
    "print(f\"   Invalid dates: {invalid_dates}\")\n",
    "if invalid_dates == 0:\n",
    "    print(f\"   ‚úÖ All dates valid\")\n",
    "    # Check that due dates are after issue dates\n",
    "    dates_logical = (invoices_df['due_date_parsed'] >= invoices_df['issue_date_parsed']).all()\n",
    "    print(f\"   ‚úÖ Due dates after issue dates: {dates_logical}\")\n",
    "\n",
    "# Status distribution\n",
    "print(\"\\n4. Invoice Status Distribution:\")\n",
    "status_dist = invoices_df['status'].value_counts()\n",
    "for status, count in status_dist.items():\n",
    "    percentage = (count / len(invoices_df)) * 100\n",
    "    amount_total = invoices_df[invoices_df['status'] == status]['amount'].sum()\n",
    "    print(f\"   - {status}: {count} invoices ({percentage:.1f}%) - KES {amount_total:,.2f}\")\n",
    "\n",
    "# Collection rate\n",
    "collection_rate = (invoices_df['amount_paid'].sum() / invoices_df['amount'].sum()) * 100\n",
    "print(f\"\\n5. Collection Rate: {collection_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb4946",
   "metadata": {},
   "source": [
    "## 3. Receipts Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a00ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load receipts data\n",
    "receipts_path = Path('../data/synthetic/receipts.json')\n",
    "with open(receipts_path, 'r') as f:\n",
    "    receipts_data = json.load(f)\n",
    "\n",
    "receipts_df = pd.DataFrame(receipts_data)\n",
    "\n",
    "print(f\"üßæ Receipts Dataset loaded: {len(receipts_df)} records\")\n",
    "print(f\"\\nDataset shape: {receipts_df.shape}\")\n",
    "print(f\"\\nColumns: {list(receipts_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 5 receipts\n",
    "print(\"\\nüìã First 5 Receipts:\\n\")\n",
    "receipts_df[['receipt_id', 'vendor', 'category', 'total', 'payment_method', 'date']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3cabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receipts Data Validation\n",
    "print(\"\\nüîç Receipts Data Validation:\\n\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"1. Missing Values:\")\n",
    "missing = receipts_df.isnull().sum()\n",
    "print(missing[missing > 0] if missing.sum() > 0 else \"   ‚úÖ No missing values in critical fields\")\n",
    "\n",
    "# Check amounts are valid\n",
    "print(\"\\n2. Amount Validation:\")\n",
    "print(f\"   Min receipt: KES {receipts_df['total'].min():,.2f}\")\n",
    "print(f\"   Max receipt: KES {receipts_df['total'].max():,.2f}\")\n",
    "print(f\"   Total expenses: KES {receipts_df['total'].sum():,.2f}\")\n",
    "print(f\"   Total tax (VAT): KES {receipts_df['tax'].sum():,.2f}\")\n",
    "\n",
    "# Verify tax calculations (should be ~16% for items with tax)\n",
    "receipts_with_tax = receipts_df[receipts_df['tax'] > 0]\n",
    "if len(receipts_with_tax) > 0:\n",
    "    avg_tax_rate = (receipts_with_tax['tax'] / receipts_with_tax['subtotal']).mean() * 100\n",
    "    print(f\"   Average tax rate: {avg_tax_rate:.1f}% (Expected: 16%)\")\n",
    "\n",
    "# Check date validity\n",
    "print(\"\\n3. Date Validation:\")\n",
    "receipts_df['date_parsed'] = pd.to_datetime(receipts_df['date'], errors='coerce')\n",
    "invalid_dates = receipts_df['date_parsed'].isnull().sum()\n",
    "print(f\"   Invalid dates: {invalid_dates}\")\n",
    "if invalid_dates == 0:\n",
    "    print(f\"   ‚úÖ All dates valid\")\n",
    "    print(f\"   Date range: {receipts_df['date_parsed'].min().date()} to {receipts_df['date_parsed'].max().date()}\")\n",
    "\n",
    "# Category distribution\n",
    "print(\"\\n4. Expense Category Distribution:\")\n",
    "category_dist = receipts_df.groupby('category')['total'].agg(['count', 'sum'])\n",
    "category_dist = category_dist.sort_values('sum', ascending=False)\n",
    "for idx, row in category_dist.iterrows():\n",
    "    percentage = (row['sum'] / receipts_df['total'].sum()) * 100\n",
    "    print(f\"   - {idx}: {int(row['count'])} receipts, KES {row['sum']:,.2f} ({percentage:.1f}%)\")\n",
    "\n",
    "# Payment method distribution\n",
    "print(\"\\n5. Payment Method Distribution:\")\n",
    "payment_dist = receipts_df['payment_method'].value_counts()\n",
    "for method, count in payment_dist.items():\n",
    "    percentage = (count / len(receipts_df)) * 100\n",
    "    print(f\"   - {method}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Reimbursable expenses\n",
    "reimbursable_total = receipts_df[receipts_df['is_reimbursable']]['total'].sum()\n",
    "reimbursable_count = receipts_df['is_reimbursable'].sum()\n",
    "print(f\"\\n6. Reimbursable Expenses:\")\n",
    "print(f\"   Count: {reimbursable_count}\")\n",
    "print(f\"   Total: KES {reimbursable_total:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efac2e4",
   "metadata": {},
   "source": [
    "## Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n1. SMS Messages: {len(sms_df)} records\")\n",
    "print(f\"   - Total transaction value: KES {sms_df['amount'].sum():,.2f}\")\n",
    "print(f\"   - Transaction types: {sms_df['transaction_type'].nunique()}\")\n",
    "\n",
    "print(f\"\\n2. Invoices: {len(invoices_df)} records\")\n",
    "print(f\"   - Total invoice value: KES {invoices_df['amount'].sum():,.2f}\")\n",
    "print(f\"   - Total collected: KES {invoices_df['amount_paid'].sum():,.2f}\")\n",
    "print(f\"   - Collection rate: {(invoices_df['amount_paid'].sum() / invoices_df['amount'].sum() * 100):.1f}%\")\n",
    "\n",
    "print(f\"\\n3. Receipts: {len(receipts_df)} records\")\n",
    "print(f\"   - Total expenses: KES {receipts_df['total'].sum():,.2f}\")\n",
    "print(f\"   - Expense categories: {receipts_df['category'].nunique()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ALL DATASETS VALIDATED SUCCESSFULLY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüéØ These datasets are ready for:\")\n",
    "print(\"   ‚Ä¢ Milestone 3: SMS Parser Tool development\")\n",
    "print(\"   ‚Ä¢ Milestone 4: Insights Tool development\")\n",
    "print(\"   ‚Ä¢ Milestone 5: Invoice Collection Tool development\")\n",
    "print(\"   ‚Ä¢ ADK Agent testing and integration\")\n",
    "\n",
    "print(\"\\nüìù Data Quality:\")\n",
    "print(\"   ‚úÖ No missing critical values\")\n",
    "print(\"   ‚úÖ All amounts are valid and positive\")\n",
    "print(\"   ‚úÖ All dates are valid and properly formatted\")\n",
    "print(\"   ‚úÖ Realistic distributions for Kenyan SMEs\")\n",
    "print(\"   ‚úÖ Consistent data structures across datasets\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
